{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import PIL\n",
    "import imageio\n",
    "import random\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "from UtilityTest import DepthDataset\n",
    "from UtilityTest import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Location_video='/workspace/test_vid/VID_20200102_142929.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the video from zipfile\n",
    "from zipfile import ZipFile\n",
    "zf = ZipFile('/workspace/test_vid.zip', 'r')\n",
    "zf.extractall('/workspace/')\n",
    "zf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting video into frames\n",
    "vidcap = cv2.VideoCapture(Location_video)\n",
    "success,image = vidcap.read()\n",
    "count = 0\n",
    "while success:\n",
    "  cv2.imwrite(\"/workspace/test_vid/Frames/frame%d.jpg\" % count, image)     # save frame as JPEG file      \n",
    "  success,image = vidcap.read()\n",
    "  print('Read a new frame: ', success)\n",
    "  count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location of video frames\n",
    "loc_img='/workspace/test_vid/Frames/'\n",
    "\n",
    "#ploting few sample frames\n",
    "depth_dataset = DepthDataset(root_dir=loc_img)\n",
    "fig = plt.figure()\n",
    "len(depth_dataset)\n",
    "for i in range(len(depth_dataset)):\n",
    "    sample = depth_dataset[i]\n",
    "\n",
    "    print(i, sample['image'].size)\n",
    "\n",
    "\n",
    "    plt.imshow(sample['image'])\n",
    "    plt.figure()\n",
    "\n",
    "\n",
    "    if i == 2:\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_dataset = DepthDataset(root_dir=loc_img,transform=transforms.Compose([ToTensor()]))\n",
    "# depth_dataset\n",
    "batch_size=1\n",
    "train_loader=torch.utils.data.DataLoader(depth_dataset, batch_size)\n",
    "# train_loader\n",
    "dataiter = iter(train_loader)\n",
    "images = dataiter.next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils as utils\n",
    "import torchvision.utils as vutils    \n",
    "import torchvision.models as models\n",
    "from Mobile_model import Model\n",
    "model = Model().cuda()\n",
    "model = nn.DataParallel(model)\n",
    "#loading the the trained model\n",
    "model.load_state_dict(torch.load('/workspace/17.pth'))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('/workspace/test_vid/depth_frames/')\n",
    "\n",
    "#generating the depth image of frames\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "for i,sample_batched1  in enumerate (train_loader):\n",
    "    image1 = torch.autograd.Variable(sample_batched1['image'].cuda())\n",
    "    \n",
    "    outtt=model(image1 )\n",
    "    x=outtt.detach().cpu().numpy()\n",
    "    x.shape\n",
    "    x=x.reshape(240,320)\n",
    "    img=x\n",
    "    scale_percent = 200 # percent of original size\n",
    "    width = int(img.shape[1] * scale_percent / 100)\n",
    "    height = int(img.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    # resize image\n",
    "    resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    plt.imsave('/workspace/test_vid/depth_frames/geeks%d.jpg' %i, resized, cmap='inferno')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import isfile, join\n",
    " \n",
    "def convert_frames_to_video(pathIn,pathOut,fps):\n",
    "    frame_array = []\n",
    "    files = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]\n",
    " \n",
    "    #for sorting the file names properly\n",
    "    files.sort(key = lambda x: int(x[5:-4]))\n",
    " \n",
    "    for i in range(len(files)):\n",
    "        filename=pathIn + files[i]\n",
    "        #reading each files\n",
    "        img = cv2.imread(filename)\n",
    "        height, width, layers = img.shape\n",
    "        size = (width,height)\n",
    "        print(filename)\n",
    "        #inserting the frames into an image array\n",
    "        frame_array.append(img)\n",
    " \n",
    "    out = cv2.VideoWriter(pathOut,cv2.VideoWriter_fourcc(*'MP4V'), fps, size)\n",
    " \n",
    "    for i in range(len(frame_array)):\n",
    "        # writing to a image array\n",
    "        out.write(frame_array[i])\n",
    "    out.release()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #convert frames to videos\n",
    "    pathIn= '/workspace/test_vid/depth_frames/'\n",
    "    pathOut = '/workspace/test_vid/video1.mp4'\n",
    "    #enter the correct frame rates\n",
    "    fps = 30.01\n",
    "    convert_frames_to_video(pathIn, pathOut, fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the frames to gif\n",
    "\n",
    "filenames='/workspace/test_vid/depth_frames/'\n",
    "files = [f for f in os.listdir(filenames) if isfile(join(filenames, f))]\n",
    "\n",
    "files.sort(key = lambda x: int(float(x[5:-4])))\n",
    "files\n",
    "images = []\n",
    "for i,filename in enumerate(files):\n",
    "    if i%10==0:\n",
    "        images.append(imageio.imread(os.path.join('/workspace/test_vid/depth_frames/',filename)))\n",
    "        print(filename)\n",
    "imageio.mimsave('/workspace/test_vid/movie_depth.gif', images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import transform,io\n",
    "filenames='/workspace/test_vid/Frames/'\n",
    "files = [f for f in os.listdir(filenames) if isfile(join(filenames, f))]\n",
    "\n",
    "files.sort(key = lambda x: int(float(x[5:-4])))\n",
    "files\n",
    "images = []\n",
    "for i,filename in enumerate(files):\n",
    "    if i%10==0:\n",
    "       \n",
    "\n",
    "            # resize to 28x28\n",
    "        grey=(imageio.imread(os.path.join('/workspace/test_vid/Frames/',filename)))\n",
    "        image = transform.resize(grey, (480,640), mode='symmetric', preserve_range=True)\n",
    "        images.append(image)\n",
    "        print(filename)\n",
    "imageio.mimsave('/workspace/test_vid/movie_real.gif', images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
